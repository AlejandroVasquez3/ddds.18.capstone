{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run this in your first cell\n",
        "!pip install psycopg2-binary pandas sqlalchemy geopandas folium plotly"
      ],
      "metadata": {
        "id": "Sy8m-9cLaUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Jgq3PyQ9ZiVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-zQHVSiZcnO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# You'll need to store your database password/paramenters in Colab Secrets\n",
        "DB_HOST = userdata.get('DB_HOST')\n",
        "DB_PORT = userdata.get('DB_PORT')\n",
        "DB_PASSWORD = userdata.get('DB_PASSWORD')\n",
        "DB_USER = userdata.get(\"DB_USER\")\n",
        "DB_NAME = userdata.get('DB_NAME')\n",
        "\n",
        "\n",
        "# Create connection string\n",
        "connection_string = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "print(\"âœ… Database connection established!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: add in the msg_time column once the database has started including it\n",
        "with engine.connect() as connection:\n",
        "    captured_data = pd.read_sql_query(\n",
        "        '''\n",
        "        -- latest 100 entries give location back as latitude and longitude\n",
        "        SELECT\n",
        "          \"vehicle_snapshots\".*,\n",
        "          ST_X(\"vehicle_snapshots\".\"location\") AS longitude,\n",
        "          ST_Y(\"vehicle_snapshots\".\"location\") AS latitude\n",
        "        FROM\n",
        "          \"vehicle_snapshots\"\n",
        "        ORDER BY\n",
        "          \"id\" DESC\n",
        "        NULLS LAST\n",
        "        LIMIT\n",
        "          100;\n",
        "        ''', connection)\n",
        "\n",
        "captured_data.head()"
      ],
      "metadata": {
        "id": "01rVVzURbD12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captured_data.info()"
      ],
      "metadata": {
        "id": "2WAEhBWAhtef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parquet Export"
      ],
      "metadata": {
        "id": "0gtXAJQDcPES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarrow"
      ],
      "metadata": {
        "id": "QYsfPe64cwMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "FMKOnLxhe-3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "captured_data.to_parquet(f'abq_transit_data_{timestamp}.parquet', index=False)"
      ],
      "metadata": {
        "id": "FpOMmNE6bE5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}